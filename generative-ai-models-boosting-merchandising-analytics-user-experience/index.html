<!doctype html><html><head><meta charset=UTF-8><meta content="IE=edge,chrome=1" http-equiv=X-UA-Compatible><meta content="width=device-width,minimum-scale=1" name=viewport><title>Sergio Carracedo | Generative AI Models: Boosting Merchandising Analytics User Experience</title>
<meta content="yes" name=apple-mobile-web-app-capable><meta content="black-translucent" name=apple-mobile-web-app-status-bar-style><meta content="Sergio Carracedo's personal page and blog" name=description><meta content="Sergio Carracedo" name=author><link href=/favicon.png rel=icon><meta property="og:title" content="Generative AI Models: Boosting Merchandising Analytics User Experience"><meta property="og:description" content="This article was published originally in DZone. I wrote it in collaboration with Miguel García
In this article, we will explain how using the new Generative AI Models (LLM) can improve the experience of business users on our analytical platform. Let&rsquo;s say we provide our retail merchandising managers with a web application or a mobile application where they can analyze sales and stock behavior in real-time using natural language."><meta property="og:type" content="article"><meta property="og:url" content="https://sergiocarracedo.es/generative-ai-models-boosting-merchandising-analytics-user-experience/"><meta property="og:image" content="https://sergiocarracedo.es/generative-ai-models-boosting-merchandising-analytics-user-experience/pexels-ksenia-chernaya-3965540_hue3e183c5fa902cd4ae789f3e908b1fee_347649_1920x1080_fill_q75_box_center.jpg"><meta name=twitter:image content="https://sergiocarracedo.es/generative-ai-models-boosting-merchandising-analytics-user-experience/pexels-ksenia-chernaya-3965540_hue3e183c5fa902cd4ae789f3e908b1fee_347649_1920x1080_fill_q75_box_center.jpg"></meta><meta property="article:section" content="blog">
<meta property="article:published_time" content="2023-06-29T00:00:00+00:00"><meta property="article:modified_time" content="2023-06-29T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"></meta>
<link rel=canonical href=https://dzone.com/articles/chatgpt-boosting-merchandising-user-experience><link href=https://sergiocarracedo.es/scss/main.df9c25ee4c710877f41c3c839cb8b49ab42cafd33e26da951f93e602ac49fcf6.css integrity="sha256-35wl7kxxCHf0HDyDnLi0mrQsr9M+JtqVH5PmAqxJ/PY=" rel=stylesheet><link href=//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css rel=stylesheet type=text/css></head><body><header class=web-header><h2><a class=back-to-home href=/ title="Back to home"><i class="fas fa-home"></i><div class=back-to-home__content><span class=back-to-home__action>Back to home</span><div class=back-to-home__title><img alt="Sergio Carracedo" class=avatar src=/i/sergiocarracedo_hu6caa808ff324b89bfea4b9d7d1c850ee_80590_100x100_fit_q75_box.jpg><h4>Sergio Carracedo</h4></div></div></a></h2><div class=web-header__page-title><span>Generative AI Models: Boosting Merchandising Analytics User Experience</span></div><div class=theme-switch><i class="theme-switch__theme fas fa-sun" id=theme-switch-light title="Switch to light theme"></i>
<i class="theme-switch__theme fas fa-moon" id=theme-switch-dark title="Switch to dark theme"></i></div></header><div class=main-content><article class="post post--single"><div class="post__main wrapper-1200"><aside class=post__metadata><time class=post__date datetime=2023-06-29><i class="far fa-calendar-alt"></i> Jun 29, 2023</time><div class=post__tags><a href=https://sergiocarracedo.es/tags/frontend class=post__tag><span>frontend</span>
</a><a href=https://sergiocarracedo.es/tags/ai class=post__tag><span>ai</span></a></div><span class=post__reading-time><i class="far fa-clock"></i> 8 minutes read</span></aside><header class=post__header><h1 class=post__title>Generative AI Models: Boosting Merchandising Analytics User Experience</h1></header><figure class=post__cover><img src=/generative-ai-models-boosting-merchandising-analytics-user-experience/pexels-ksenia-chernaya-3965540_hue3e183c5fa902cd4ae789f3e908b1fee_347649_1200x400_fill_q75_box_center.jpg alt="Generative AI Models: Boosting Merchandising Analytics User Experience" width=1200 height=400></figure><div class=post__content><blockquote><p>This article was published originally in <a href=https://dzone.com/articles/chatgpt-boosting-merchandising-user-experience>DZone</a>.
I wrote it in collaboration with <a href=https://www.linkedin.com/in/mgarlorenzo/>Miguel García</a></p></blockquote><p>In this article, we will explain how using the new Generative AI Models (<a href=https://en.wikipedia.org/wiki/Large_language_model>LLM</a>) can improve the experience of business users on our <a href=https://dzone.com/articles/business-analytics-tools-amp-use-cases>analytical platform</a>. Let&rsquo;s say we provide our retail merchandising managers with a web application or a mobile application where they can analyze sales and stock behavior in real-time using natural language.</p><p>These applications usually have a series of restrictions that mainly show a generic type of analysis, which users can filter or segment based on some filters and provide information such as:</p><ul><li>Sales behavior</li><li>Sell-through</li><li>Stockouts</li><li>Stock behavior</li></ul><p>All these data, with greater or lesser granularity, answer questions that someone has previously determined. The problem is that not all users have the same questions, and sometimes the level of customization is so high that it turns the solution into a big whale. Most of the time, the information is available, but there is no time to include it in the web application.</p><p>In the last few years, there have been low code solutions on the market that try to speed up the development of applications precisely to respond as quickly as possible to the needs of this type of user. All these platforms require some technical knowledge. LLM models allow us to interact in natural language with our users and translate their questions into code and calls to the APIs in our platform that will be able to provide valuable information to them in an agile way.</p><h2 id=generative-ai-merchandising-platform-use-cases>Generative AI Merchandising Platform Use Cases</h2><p>To enhance our merchandising platform, we can include two use cases:</p><h3 id=1-iterative-business-analytical-questions>1. Iterative Business Analytical Questions</h3><p>Allow business users to ask iterative questions about the data we have in our data platform with the following capabilities:</p><ul><li>Being able to ask questions in natural languageIt can be interactive, but it must also allow the user to save his personalized questions.</li><li>The answers will be based on the updated data.</li></ul><h3 id=2-story-telling>2. Story Telling</h3><p>When you provide data to the business user about the sharing of the sale, a fundamental part is storytelling. this enhances comprehension and converts data into valuable information. It would be great if we can give the user the ability to get this explanation in natural language instead of the user having to interpret the metrics.</p><h2 id=practical-example-designing-chat-merchandising>Practical Example: Designing Chat Merchandising</h2><h3 id=overview>Overview</h3><p>It is a very simple idea to implement, and with a lot of business value for users, we are going to train our LLM model to be able to give a question, to know which data service provides the information. To do this, our architecture must meet three requirements:</p><ul><li>All data is exposed via APIs.</li><li>All data entities are defined and documented.</li><li>We have a standardized API layer.</li><li></li></ul><p>The following diagram shows the architecture of this high-level solution:</p><p><img alt=Architecture src=/generative-ai-models-boosting-merchandising-analytics-user-experience/architecture.png></p><ul><li><strong>Merchandising AI Web Platform</strong>: Web channel based on Vue through users using chat merchandising.</li><li><strong>Data Service</strong>: It provides an API Rest to consume the business data entities available in the data platform.</li><li><strong>Chat Merchandising Engine</strong>: Python backend service that performs the integration between the front and the LLM service; in this case, we are using the Open AI API.</li><li><strong>Open AI</strong>: It provides a Rest API to access Generative AI models.</li><li><strong>Business Data Domain and Data Repository</strong>: A new generation data warehouse, such as Snowflake, modeled on data domains in which business entities are available.</li><li></li></ul><p>In this PoC, we have used the OpenAI service, but you could use any other SaaS or deploy your LLM; another important point is that in this use case, <strong>we do not send any business data to the OpenAI service because all the LLM model does is translate the request made by the user in natural language into requests to our data services.</strong></p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/CdQzcEDeiYA style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=merchandising-ai-web-platform>Merchandising AI Web Platform</h3><p>With the LLM and generative UI, the frontend acquires a new relevance, a way user interacts with it, and how the frontend responds to the interactions; now we have a new actor, the Generative AI, that needs to interact with the front end to manage the user request.</p><p>The front end needs to provide context to the user messages and be able to show the response in the way the user wants. In this PoC, we will have different types of responses from the model:</p><p><strong>An array of data to display in a table:</strong></p><p><img alt=img.png src=/generative-ai-models-boosting-merchandising-analytics-user-experience/img.png></p><p><strong>An array of data to display in a chart:</strong></p><p><img alt=img_1.png src=/generative-ai-models-boosting-merchandising-analytics-user-experience/img_1.png></p><p>The front end needs to know how the model or what the user wants to see in the response to act as required; for example, if the user asks for a chart, the front end needs to render a chart; if it asks for a table, the frontend should render a table, if it&rsquo;s just tested, then show the text (and even if there is an error we should show it in a different way).</p><p>We type the Chat Merchandise Engine response (in both the back end and front end) in consequence:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-ts data-lang=ts><span style=display:flex><span><span style=color:#66d9ef>export</span> <span style=color:#66d9ef>interface</span> <span style=color:#a6e22e>TextChatResponse</span> {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>type</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;text&#39;</span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>text</span>: <span style=color:#66d9ef>string</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>export</span> <span style=color:#66d9ef>interface</span> <span style=color:#a6e22e>TableDataChatResponse</span> {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>type</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;table-data&#39;</span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>data</span>: <span style=color:#66d9ef>TableData</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>export</span> <span style=color:#66d9ef>interface</span> <span style=color:#a6e22e>ChartChatResponse</span> {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>type</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;chart&#39;</span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>options</span>: <span style=color:#66d9ef>EChartOptions</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>export</span> <span style=color:#66d9ef>interface</span> <span style=color:#a6e22e>ErrorChatResponse</span> {
</span></span><span style=display:flex><span>  <span style=color:#66d9ef>type</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#39;error&#39;</span>
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>error</span>: <span style=color:#66d9ef>string</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>export</span> <span style=color:#66d9ef>type</span> <span style=color:#a6e22e>ChatResponse</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>TextChatResponse</span> <span style=color:#f92672>|</span> <span style=color:#a6e22e>TableDataChatResponse</span> <span style=color:#f92672>|</span> <span style=color:#a6e22e>ErrorChatResponse</span> <span style=color:#f92672>|</span> <span style=color:#a6e22e>ChartChatResponse</span>
</span></span></code></pre></div><p>And this is how we decide which component show.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-vue data-lang=vue><span style=display:flex><span>&lt;<span style=color:#f92672>div</span> <span style=color:#a6e22e>class</span><span style=color:#f92672>=</span><span style=color:#e6db74>&#34;chat-messages&#34;</span>&gt;
</span></span><span style=display:flex><span>  &lt;<span style=color:#f92672>template</span> <span style=color:#f92672>v-for</span><span style=color:#e6db74>=&#34;(message, index) in messages&#34; </span><span style=color:#f92672>:key</span><span style=color:#e6db74>=&#34;index&#34;</span>&gt;          
</span></span><span style=display:flex><span>	&lt;<span style=color:#f92672>q-chat-message</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>v-if</span><span style=color:#e6db74>=&#34;message.type === &#39;text&#39;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      :avatar=&#34;message.avatar&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      :name=&#34;message.name&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      :sent=&#34;message.sent&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      :text=&#34;message.text&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    /&gt;    
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &lt;div class=&#34;chart&#34; v-if=&#34;message.type === &#39;chart&#39;&#34;&gt;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      &lt;v-chart :option=&#34;message.options&#34; autoresize class=&#34;chart&#34;/&gt;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &lt;/div&gt;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>    &lt;div class=&#34;table-wrapper&#34;  v-if=&#34;message.type === &#39;table-data&#39;&#34;</span>&gt;
</span></span><span style=display:flex><span>	  &lt;<span style=color:#f92672>q-table</span> <span style=color:#f92672>:columns</span><span style=color:#e6db74>=&#34;getTableCols(message.data)&#34;</span> <span style=color:#f92672>:rows</span><span style=color:#e6db74>=&#34;message.data&#34;</span> <span style=color:#a6e22e>dense</span>&gt;<span style=color:#f92672>&lt;</span><span style=color:#960050;background-color:#1e0010>/q-table&gt;</span>
</span></span><span style=display:flex><span>    &lt;/<span style=color:#f92672>div</span>&gt;
</span></span><span style=display:flex><span>  &lt;/<span style=color:#f92672>template</span>&gt;
</span></span><span style=display:flex><span>&lt;/<span style=color:#f92672>div</span>&gt;
</span></span></code></pre></div><p>With this approach, the frontend can receive the messages in a structured way and know how to display the data: as text, as a table, as a chart, or anything you can think of, and also is very useful for the backend as it can get data for side channels.</p><p>Regarding charts, you configure all relative to the chart in a JS object (for any type of chart), so in the next iteration of the PoC, you could ask the model for this object, and it can tell us how to render the chart, even the chart type that fits better the data, etc.</p><h3 id=chat-merchandising-engine>Chat Merchandising Engine</h3><p>The logic we have in the engine is very simple: its responsibility is only to act as a gateway between the front end, the Open AI service, and our data services. It is only necessary because the Open AI model is not trained in the context of our services. Our engine is responsible for providing that context. If the model were trained, the little logic we include in this engine would be in the front-end services layer.</p><p><img alt=img_2.png src=/generative-ai-models-boosting-merchandising-analytics-user-experience/img_2.png></p><p>We have implemented this service with Python since <a href=https://platform.openai.com/docs/api-reference/chat>Open AI</a> provides a library to facilitate integration with its APIs. We are using <a href=https://platform.openai.com/docs/api-reference/chat>chat completion API</a> (model gpt-3.5-turbo), but we could use the new feature <a href=https://platform.openai.com/docs/guides/gpt/function-calling>function-calling</a> (model gpt-3.5-turbo-0613).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Initial context</span>
</span></span><span style=display:flex><span>messages<span style=color:#f92672>=</span>[
</span></span><span style=display:flex><span>            {<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;system&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: API_description_context},
</span></span><span style=display:flex><span>            {<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;system&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: load_openapi_specification_from_yaml_to_string()},
</span></span><span style=display:flex><span>            {<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;system&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: entities},
</span></span><span style=display:flex><span>        ]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Add User Query to messages array</span>
</span></span><span style=display:flex><span>messages<span style=color:#f92672>.</span>append({<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: user_input})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Call Open AI API</span>
</span></span><span style=display:flex><span>response <span style=color:#f92672>=</span> openai<span style=color:#f92672>.</span>ChatCompletion<span style=color:#f92672>.</span>create(
</span></span><span style=display:flex><span>  model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-3.5-turbo&#34;</span>,
</span></span><span style=display:flex><span>  messages<span style=color:#f92672>=</span>messages,
</span></span><span style=display:flex><span>  temperature<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Get messages</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>generated_texts <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>            choice<span style=color:#f92672>.</span>message[<span style=color:#e6db74>&#34;content&#34;</span>]<span style=color:#f92672>.</span>strip() <span style=color:#66d9ef>for</span> choice <span style=color:#f92672>in</span> response[<span style=color:#e6db74>&#34;choices&#34;</span>]
</span></span><span style=display:flex><span>        ]
</span></span></code></pre></div><p>We have composed the context in a natural language description that includes some examples, the API specification, and the definition of the APIs.</p><pre tabindex=0><code>Merchandasing Data Service is an information query API, based on OPEN API 3, 
this is an example of URL http://{business_domain}.retail.co/data/api/v1/{{entity}}.
  
Following parameters are included in the API: &#34;fields&#34; to specify the attributes of the entity that we want to get; 
&#34;filter&#34; to specify the conditions that must satisfy the search;

For example to answer the question of retrieving the products that are not equal to the JEANS family a value 
would be  products that are not equal to the JEANS family a value would be filter=familyName%%20ne%%20JEANS
</code></pre><p>We parse the response and obtain the generated URL using a regular expression, although we could opt for another strategy using some special quotes.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>find_urls</span>(model_message_response):
</span></span><span style=display:flex><span>    <span style=color:#75715e># Patrón para encontrar URLs</span>
</span></span><span style=display:flex><span>    url_pattern <span style=color:#f92672>=</span> re<span style=color:#f92672>.</span>compile(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#39;http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*</span><span style=color:#ae81ff>\\</span><span style=color:#e6db74>(</span><span style=color:#ae81ff>\\</span><span style=color:#e6db74>),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+&#39;</span>)
</span></span><span style=display:flex><span>    urls <span style=color:#f92672>=</span> re<span style=color:#f92672>.</span>findall(url_pattern, model_message_response)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> urls
</span></span></code></pre></div><p>We also asked the model to add a fragment (for example, #chart) to the URL allowing us to know what the user expects to see in the frontend</p><p>This solution is much better than searching for a string in the user input because the user can ask for a chart without using the chart word, which is the model, that “understand” the question of who decides to use the chart representation.</p><p>Finally, we send this answer back to the front because the call to the data services is made from the front end itself, and this allows us to consume the data services using the user&rsquo;s own JWT tokens.</p><h2 id=conclusions>Conclusions</h2><p>During the last years, many organizations and teams have worked on having an agile architecture, good data governance, and an API strategy that allows them to adapt to changes in an agile way. Generative AI models can provide great business value, and it takes very little effort to start delivering value.</p><p>We develop this PoC you can see in the video, in a few hours, using Vue3, Quasar Ui for the basic components and the table, and Echarts to render the charts and Open AI. There is no doubt that algorithms are the new trend and will also be the key to the data-driven strategy; organizations that start from a standardized and agile architecture have a head start in this challenge.</p></div></div><aside class=post__nav-wrapper><div class=wrapper-1200><div class="post-nav post-nav--prev"><a class=post-nav__link href="https://sergiocarracedo.es/stream-deck-linux/?ref=footer"><div class=post-nav__cover><img alt=.NextPage.Title src=/stream-deck-linux/cover_hu5b29a43d430f177bf973b756f5829c02_162384_200x120_fill_q75_box_center.jpg></div><div class=post-nav__title>elgato Stream Deck on Linux</div></a></div><div class=blog-link><a class=btn href=https://sergiocarracedo.es/blog>All Blog posts</a></div><div class="post-nav post-nav--next"><a class=post-nav__link href="https://sergiocarracedo.es/front-end-cache-strategies-you-should-know/?ref=footer"><div class=post-nav__cover><img alt=.PrevPage.Title class=post-nav__cover src=/front-end-cache-strategies-you-should-know/_hub1ae221aa178f21b1687a813d198d8bd_266521_665ed32eeb2b143d3edf1618e44f2e51.jpeg></div><div class=post-nav__title>Front-End: Cache Strategies You Should Know</div></a></div></div></aside><aside class=post__search-wrapper><div class=wrapper-1200>Search in this blog:<form class=search-form action=https://sergiocarracedo.es/search method=get><label hidden for=search-input>Search</label>
<input type=text id=search-input name=query placeholder=Search class=search-form__input>
<button class=search-form__button>
<i class="fas fa-search"></i></button></form></div></aside><aside class=post__comments><div class=wrapper-1200><div id=disqus_thread>To show the comments is mandatory accept cookie policy.</div></div></aside></article></div><footer class=web-footer><div class=wrapper-1200><div class=web-footer__left><div class=me><div class=me__avatar><img alt="Sergio Carracedo" src=/i/sergiocarracedo_hu6caa808ff324b89bfea4b9d7d1c850ee_80590_170x170_fit_q75_box.jpg></div><div class=me__titles><h1>Sergio Carracedo</h1><h2>Senior Fullstack developer.</h2><h3>Always learning, cats, good conversations and small details lover.</h3></div></div></div><div class=web-footer__right><nav role=main class=menu><ul><li class=menu__item><a href=https://sergiocarracedo.es/>Home</a></li><li class=menu__item><a href=https://sergiocarracedo.es/blog>Blog</a></li></ul></nav><div class=social><a class=social__link href=http://www.linkedin.com/in/sergiocarracedo target=_blank title=LinkedIn style=animation-delay:2s><i class="fab fa-linkedin"></i>
</a><a class=social__link href=mailto:hi+blog@sergiocarracedo.es target=_blank title=Email style=animation-delay:1.9333333333333333s><i class="fas fa-envelope"></i>
</a><a class=social__link href=https://github.com/sergiocarracedo target=_blank title=GitHub style=animation-delay:1.8666666666666667s><i class="fab fa-github"></i>
</a><a class=social__link href=https://www.drupal.org/u/sergiocarracedo target=_blank title=Drupal style=animation-delay:1.8s><i class="fab fa-drupal"></i>
</a><a class=social__link href=https://www.twitter.com/sergiocarracedo target=_blank title=Twitter style=animation-delay:1.7333333333333334s><i class="fab fa-twitter"></i>
</a><a class=social__link href=http://www.last.fm/user/gasman40 target=_blank title=Last.fm style=animation-delay:1.6666666666666667s><i class="fab fa-lastfm"></i>
</a><a class=social__link href=http://sergiocarracedo.tumblr.com/ target=_blank title=Tumblr style=animation-delay:1.6s><i class="fab fa-tumblr"></i></a></div></div></div></footer><script async src="https://www.googletagmanager.com/gtag/js?id=G-87X78TXEGE"></script><script>function runGA(){window.dataLayer=window.dataLayer||[];function e(){dataLayer.push(arguments)}e("js",new Date),e("config","G-87X78TXEGE")}</script><script>function runDisqus(){(function(){var e=document,t=e.createElement("script");t.src="https://sergiocarracedo.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()}</script><script src=//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js></script><script>window.addEventListener("load",function(){window.cookieconsent.initialise({palette:{popup:{background:"#004262",text:"#fff"},button:{background:"#8ec760",text:"#ffffff"}},type:"opt-out",content:{message:"Este sitio usa cookies propias y de terceros para mejorar la experiencia de usuario y esas cosas.",allow:"Ok, continua",deny:"Nada de cookies",link:"Saber más",href:"https://sergiocarracedo.es/cookies"},onStatusChange:function(e){e=="allow"&&runCookiesAllowed()},onInitialise:function(e){e=="allow"&&runCookiesAllowed()}})})</script><script>addEventListener("scroll",e=>{let t=document.getElementsByTagName("body")[0];t&&window.scrollY>10?t.classList.add("not-in-top"):t.classList.remove("not-in-top")});function runCookiesAllowed(){runGA(),runDisqus()}</script><script integrity="sha256-iiQa3rTjie3Ydsr4WEu2+aLDTaxKKVR3ZTwTYrRUjXs=" src=https://sergiocarracedo.es/js/theme.8a241adeb4e389edd876caf8584bb6f9a2c34dac4a295477653c1362b4548d7b.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script integrity="sha256-LVPRt2Ca+MpOY1KztdII4jRv+U0kJBcBZEvwhZr2a4Y=" src=https://sergiocarracedo.es/js/search.2d53d1b7609af8ca4e6352b3b5d208e2346ff94d24241701644bf0859af66b86.js></script></body></html>